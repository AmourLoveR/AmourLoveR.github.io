{"meta":{"title":"Amour&R'blog","subtitle":"","description":"","author":"Amour&R","url":"http://amourlover.xyz","root":"/"},"pages":[{"title":"友情链接","date":"2020-06-02T14:11:20.881Z","updated":"2020-05-09T11:47:12.000Z","comments":true,"path":"friends/index.html","permalink":"http://amourlover.xyz/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"操作系统第四章","slug":"操作系统第四章","date":"2020-06-12T15:56:21.000Z","updated":"2020-06-14T10:06:14.510Z","comments":true,"path":"2020/06/12/操作系统第四章/","link":"","permalink":"http://amourlover.xyz/2020/06/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E5%9B%9B%E7%AB%A0/","excerpt":"文件、磁盘、IO","text":"文件、磁盘、IO 初识文件管理 文件的属性 一个文件有哪些属性? 文件名:由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许有重名文件。 标识符:一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用于区分各个文件的一-种内部名称。 类型:指明文件的类型 位置:文件存放的路径(让用户使用)、在外存中的地址(操作系统使用，对用户不可见) 大小:指明文件大小 创建时间、上次修改时间文件所有者信息 保护信息:对文件进行保护的访问控制信息 文件内部的数据应该怎样组织起来？ 文件之间应该怎样组织起来？ 操作系统应该向上提供哪些功能？ 从上往下看，文件应如和存放在外存？ 其他需要由操作系统实现的文件管理功能 总结： 文件的逻辑结构 类似于数据结构的“逻辑结构”和“物理结构”。如“线性表”就是一种逻辑结构，在用户角度看来，线性表就是一组有先后关系的元素序列，如: a,b,c,d,e …. “线性表”这种逻辑结构可以用不同的物理结构实现，如:顺序表/链表。顺序表的各个元素在逻辑上相邻，在物理上也相邻;而链表的各个元素在物理.上可以是不相邻的。因此，顺序表可以实现“随机访问”，而“链表”无法实现随机访问。 可见，算法的具体实现与逻辑结构、物理结构都有关(文件也一样，文件操作的具体实现与文件的逻辑结构、物理结构都有关) 无结构文件 按文件是否有结构分类，可以分为无结构文件、有结构文件两种。 无结构文件:文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”。如:Windows操作系统中的.txt 文件。 有结构文件 有结构文件:由一组相似的记录组成，又称“记录式文件”。每条记录又若千个数据项组成。如:数据库表文件。一般来说，每条记录有一个数据项可作为关键字。根据各条记录的长度(占用的存储空间)是否相等，又可分为定长记录和可变长记录两种。 有结构文件的逻辑结构 顺序文件 顺序文件:文件中的记录-一个接一个地顺序排列(逻辑上)，记录可以是定长的或可变长的。各个记录在物理上可以顺序存储或链式存储。 注:一般来说，考试题目中所说的“顺序文件”指的是物理上顺序存储的顺序文件。之后的讲解中提到的顺序文件也默认如此。可见，顺序文件的缺点是增加/删除一个记录比较困难(如果是串结构则相对简单) 索引文件 索引表本身是定长记录的顺序文件。因此可以快速找到第i个记录对应的索引项。 可将关键字作为索引号内容，若按关键字顺序排列，则还可以支持按照关键字折半查找。 每当要增加/删除-一个记录时，需要对索引表进行修改。由于索引文件有很快的检索速度，因此主要用于对信息处理的及时性要求比较高的场合。 另外，可以用不同的数据项建立多个索引表。如:学生信息表中，可用关键字“学号”建立一张索学生信息表中，可用关键字“学号”建立一张索引表。也可用“姓名”建立- -张索引表。这样就可以根据“姓名”快速地检索文件了。(Eg:SQL就支持根据某个数据项建立索引的功能) 索引顺序文件 索引文件的缺点：每个记录对应一个索引表项，因此索引表可能会很大。比如:文件的每个记录平均只占8B，而每个索引表项占32个字节，那么索引表都要比文件内容本身大4倍，这样对存储空间的利用率就太低了。 索引顺序文件是索引文件和顺序文件思想的结合。索引顺序文件中，同样会为文件建立张索引表，但不同的是:并不是每个记录对应一一个索引表项，而是一-组记录对应一个索引表项。 多级索引顺序文件 为了进一步提高检索效率，可以为顺序文件建立多级索引表。例如，对于一个含106个记录的文件，可先为该文件建立一-张低级索引表，每100个记录为一组，故低级索引表中共有10000个表项( 即10000个定长记录)，再把这10000个定长记录分组，每组100个，为其建立顶级索引表，故顶级索引表中共有100个表项。 总结： 文件目录 文件控制块 目录文件中的一条记录就是一个“文件控制块(FCB) FCB的有序集合称为“文件目录”，一个FCB就是-一个文件目录项。FCB中包含了文件的基本信息(文件名、物理地址、逻辑结构、物理结构等)，存取控制信息(是否可读/可写、禁止访问的用户名单等)，使用信息(如文件的建立时间、修改时间等)。最重要，最基本的还是文件名、文件存放的物理地址。 FCB实现了文件名和文件之间的映射。使用户(用户程序)可以实现“按名存取” 需要对目录进行哪些操作? 搜索:当用户要使用一一个文件时，系统要根据文件名搜索目录，找到该文件对应的目录项 创建文件:创建-一个新文件时，需要在其所属的目录中增加一一个目录项 删除文件:当删除- 一个文件时，需要在目录中删除相应的目录项 显示目录:用户可以请求显示目录的内容，如显示该目录中的所有文件及相应属性 修改目录:某些文件属性保存在目录中，因此这些属性变化时需要修改相应的目录项(如:文件重命名) 目录结构 单级目录结构 早期操作系统并不支持多级目录，整个系统中只建立一张目录表，每个文件占一个目录项。 单级目录实现了“按名存取”，但是不允许文件重名。 在创建一一个文件时，需要先检查目录表中有没有重名文件，确定不重名后才能允许建立文件，并将新文件对应的目录项插入目录表中。 显然，单级目录结构不适用于多用户操作系统。 两级目录结构 早期的多用户操作系统，采用两级目录结构。分为主文件目录(MFD，Master File Directory)和用户文件目录(UFD，User Flie Directory)。 多级目录结构（树形目录结构） 用户(或用户进程)要访问某个文件时要用文件路径名标识文件，文件路径名是个字符串。各级目录之间用“/”隔开。从根目录出发的路径称为绝对路径。 例如:自拍.jpg的绝对路径是“ /照片/2015-08/自拍jpg’ 系统根据绝对路径-一层- -层地找到下- -级目录。刚开始从外存读入根目录的目录表;找到“照片”目录的存放位置后，从外存读入对应的目录表;再找到“2015-08”目录的存放位置，再从外存读入对应目录表;最后才找到文件“自拍jpg”的存放位置。整个过程需要3次读磁盘I/O操作。 很多时候，用户会连续访问同一目录内的多个文件(比如:接连查看“2015-08”目 录内的多个照片文件)，显然，每次都从根目录开始查找，是很低效的。因此可以设置-一个“当前目录”。 例如，此时已经打开了“照片”的目录文件，也就是说，这张目录表已调入内存，那么可以把它设置为“当前目录”。当用户想要访问某个文件时，可以使用从当前目录出发的“相对路径”。 在Linux中，“” 表示当前目录，因此如果“照片”是当前目录，则”自拍.jpg”的相对路径为:“./2015-08/自拍jpg”。从当前路径出发，只需要查询内存中的“照片”目录表，即可知道”2015-08”目录表的存放位置，从外存调入该目录，即可知道“自拍.jpg”存放的位置了。 可见，引入“当前目录”和“相对路径”后，磁盘I/O的次数减少了。这就提升了访问文件的效率。 缺点：树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，树形结构不便于实现文件的共享。为此，提出了“无环图目录结构”。 无环图目录结构 可以用不同的文件名指向同一个文件，甚至可以指向同一个目录(共享同一目录下的所有内容)。需要为每个共享结点设置-一个共享计数器，用于记录此时有多少个地方在共享该结点。用户提出删除结点的请求时，只是删除该用户的FCB、并使共享计数器减1，并不会直接删除共享结点。只有共享计数器减为0时，才删除结点。 注意:共享文件不同于复制文件。在共享文件中，由于各用户指向的是同一个文件，因此只要其中一个用户修改了文件数据，那么所有用户都可以看到文件数据的变化。 索引节点（FCB的改进） 思考有何好处? 假设一个FCB是64B，磁盘块的大小为1KB，则每个盘块中只能存放16个FCB。若-一个文件目录中共有640个目录项，则共需要占用640/16 = 40个盘块。因此按照某文件名检索该目录，平均需要查询320个目录项，平均需要启动磁盘20次(每次磁盘I/O读入一块)。 若使用索引结点机制，文件名占14B，索引结点指针站2B，则每个盘块可存放64个目录项，那么按文件名检索目录平均只需要读入320/64=5个磁盘块。显然，这将大大提升文件检索速度。 当找到文件名对应的目录项时，才需要将索引结点调入内存，索引结点中记录了文件的各种信息，包括文件在外存中的存放位置，根据“存放位置”即可找到文件。存放在外存中的索引结点称为“磁盘索引结点”，当索引结点放入内存后称为“内存索引结点”。相比之下内存索引结点中需要增加一些信息，比如:文件是否被修改、此时有几个进程正在访问该文件等。 总结： 文件的物理结构 文件块、磁盘块 文件分配方式 连续分配 连续分配方式要求每个文件在磁盘上占有一组连续的块。 用户给出要访问的逻辑块号，操作系统找到该文件对应的目录项(FCB) 物理块号=起始块号+逻辑块号 当然，还需要检查用户提供的逻辑块号是否合法(逻辑块号≥长度就不合法) 可以直接算出逻辑块号对应的物理块号，因此连续分配支持顺序访问和直接访问(即随机访问) 读取某个磁盘块时，需要移动磁头。访问的两个磁盘块相隔越远，移动磁头所需时间就越长。 结论：连续分配的文件在顺序读/写时速度最快 若此时文件A要拓展，需要再增加一个磁盘块(总共需要连续的4个磁盘块)。由于采用连续结构，因此由于采用连续结构，因此文件A占用的磁盘块必须是连续的。因此只能将文件A全部“迁移”到绿色区域。 结论：物理上采用连续分配的文件不方便拓展。 结论:物理上采用连续分配，存储空间利用率低，会产生难以利用的磁盘碎片可以用紧凑来处理碎片，但是需要耗费很大的时间代价。 优点:支持顺序访问和直接访问(即随机访问);连续分配的文件在顺序访问时速度最快。 缺点:不方便文件拓展;存储空间利用率低，会产生磁盘碎片。 链接分配 链接分配采取离散分配的方式，可以为文件分配离散的磁盘块。分为隐式链接和显式链接两种。 隐式链接 用户给出要访问的逻辑块号i,操作系统找到该文件对应的目录项(FCB) 从目录项中找到起始块号(即0号块)，将0号逻辑块读入内存，由此知道1号逻辑块存放的物理块号，于是读入1号逻辑块，再找到2号逻辑块的存放位置….以此类推。因此，读入i号逻辑块，总共需要i+1次磁盘I/O。 结论:采用链式分配(隐式链接)方式的文件，只支持顺序访问，不支持随机访问，查找效率低。另外，指向下一个盘块的指针也需要耗费少量的存储空间。 结论:采用隐式链接的链接分配方式，很方便文件拓展。另外，所有的空闲磁盘块都可以被利用，不会有碎片问题，外存利用率高。 隐式链接——除文件的最后一个盘块之外，每个盘块中都存有指向下一个盘块的指针。文件目录包括文件第一块的指针和最后一块的指针。 优点:很方便文件拓展，不会有碎片问题，外存利用率高。 缺点:只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量的存储空间。 2.显示连接 显式链接——把用于链接文件各物理块的指针显式地存放在一-张表中，即文件分配表(FAT, File Allocation Table)。一个磁盘只会建立一张文件分配表。开机时文件分配表放入内存，并常驻内存。 优点:很方便文件拓展，不会有碎片问题，外存利用率高，并且支持随机访问。相比于隐式链接来说，地址转换时不需要访问磁盘，因此文件的访问效率更高。 缺点:文件分配表的需要占用一定的存储空间。 索引分配 索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块(索引表的功能类似于内存管理中的页表——建立逻辑页面到物理页之间的映射关系)。索引表存放的磁盘块称为索引块。文件数据存放的磁盘块称为数据块。 用户给出要访问的逻辑块号i，操作系统找到该文件对应的目录项(FCB)… 从目录项中可知索引表存放位置，将索引表从外存读入内存，并查找索引表即可只i号逻辑块在外存中的存放位置。 可见，索引分配方式可以支持随机访问。 文件拓展也很容易实现(只需要给文件分配一个空闲块，并增加一个索引表项即可) ①链接方案:如果索引表太大，一个索引块装不下，那么可以将多个索引块链接起来存放。 ②多层索引:建立多层索引(原理类似于多级页表)。使第一层索引块指向第二层的索引块。还可根据文件大小的要求再建立第三层、第四层索引块。 采用K层索引结构，且顶级索引表未调入内存，则访问一个数据块只需要K+ 1次读磁盘操作. ③混合索引:多种索引分配方式的结合。例如，一个文件的顶级索引表中，既包含直接地址索引(直接指向数据块)，又包含- -级间接索引(指向单层索引表)、还包含两级间接索引(指向两层索引表)。 总结： 文件存储空间管理 存储空间的划分与初始化 存储空间管理方法 空闲表法 适用于“连续分配方式” 空闲链表法 空闲盘块链： 空闲盘区链： 位示图法 连续分配、离散分配都适用 成组链接法 空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大。UNIX系统中采用了成组链接法对磁盘空闲块进行管理。 文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存。并且要保证内存与外存中的“超级块”数据一致。 总结： 文件的基本操作 创建文件 进行Create系统调用时，需要提供的几个主要参数: 所需的外存空间大小(如:一个盘块，即1KB) 文件存放路径(“D:/Demo” ) 文件名(这个地方默认为“新建文本文档.txt”) 操作系统在处理Create系统调用时，主要做了两件事: 在外存中找到文件所需的空间(结合上小节学习的空闲链表法、位示图、成组链接法等管理策略，找到空闲空间) 根据文件存放路径的信息找到该目录对应的目录文件(此处就是D:/Demo目录)，在目录中创建该文件对应的目录项。目录项中包含了文件名、文件在外存中的存放位置等信息。 删除文件 进行Delete系统调用时，需要提供的几个主要参数 文件存放路径(“D:/Demo”) 文件名(“test.txt” ) 操作系统在处理Delete系统调用时，主要做了几件事: 根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的目录项。 根据该目录项记录的文件在外存的存放位置、文件大小等信息，回收文件占用的磁盘块。(回收磁盘块时，根据空闲表法、空闲链表法、位图法等管理策略的不同，需要做不同的处理) 从目录表中删除文件对应的目录项。 打开文件 在很多操作系统中，在对文件进行操作之前，要求用户先使用open系统调用“打开文件”，需要提供的几个主要参数: 文件存放路径(“D:/Demo”) 文件名(“test.txt” ) 要对文件的操作类型(如: r只读;rw读写等) 操作系统在处理open系统调用时，主要做了几件事: 根据文件存放路径找到相应的目录文件，从目录中找到文件名对应的的目录项，并检查该用户是否有指定的操作权限。 将目录项复制到内存中的“打开文件表”中。并将对应表目的编号返回给用户。之后用户使用打开文件表的编号来指明要操作的文件。 关闭文件 进程使用完文件后，要“关闭文件” 操作系统在处理Close系统调用时，主要做了几件事: 将进程的打开文件表相应表项删除 回收分配给该文件的内存空间等资源 系统打开文件表的打开计数器count减1，若count =0，则删除对应表项。 读文件 进程使用read系统调用完成写操作。需要指明是哪个文件(在支持“打开文件”操作的系统中，只需要提供文件在打开文件表中的索引号即可)，还需要指明要读入多少数据(如:读入1KB)、指明读入的数据要放在内存中的什么位置。 操作系统在处理read系统调用时，会从读指针指向的外存中，将用户指定大小的数据读入用户指定的内存区域中。 写文件 进程使用write系统调用完成写操作，需要指明是哪个文件(在支持“打开文件”操作的系统中，只需要提供文件在打开文件表中的索引号即可)，还需要指明要写出多少数据(如:写出1KB)、写回外存的数据放在内存中的什么位置。 操作系统在处理write系统调用时，会从用户指定的内存区域中，将指定大小的数据写回写指针指向的外存。 总结： 文件共享 注意:多个用户共享同一个文件，意味着系统中只有“一份”文件数据。并且只要某个用户修改了该文件的数据，其他用户也可以看到文件数据的变化。 如果是多个用户都“复制”了同一个文件，那么系统中会有“好几份”文件数据。其中一个用户修改了自己的那份文件数据，对其他用户的文件数据并没有影响。 基于索引结点的共享方式（硬链接） 知识回顾:索引结点，是一种文件目录瘦身策略。由于检索文件时只需用到文件名，因此可以将除了文件名之外的其他信息放到索引结点中。这样目录项就只需要包含文件名、索引结点指针。 索引结点中设置一个链接计数变量count,用于表示链接到本索引结点上的用户目录项数。 若count=2，说明此时有两个用户目录项链接到该索引结点上，或者说是有两个用户在共享此文件。若某个用户决定“删除”该文件，则只是要把用户目录中与该文件对应的目录项删除，且索引结点的count值减1。 若count&gt;0，说明还有别的用户要使用该文件，暂时不能把文件数据删除，否则会导致指针悬空。 当count=0时系统负责删除文件。 基于符号链的共享方式（软链接） 当User3访问“ccc”时，操作系统判断文件“ccc”属于Link类型文件，于是会根据其中记录的路径层层查找目录，最终找到User1的目录表中的“aaa” 表项，于是就找到了文件1的索引结点。 总结： 文件保护 口令保护 为文件设置一个“口令”(如: abc112233) ，用户请求访问该文件时必须提供“口令”。 口令一般存放在文件对应的FCB或索引结点中。用户访问文件前需要先输入“口令”，操作系统会将用户提供的口令与FCB中存储的口令进行对比，如果正确，则允许该用户访问文件 优点:保存口令的空间开销不多，验证口令的时间开销也很小。 缺点:正确的“口令”存放在系统内部，不够安全。 加密保护 使用某个“密码”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密。 优点:保密性强，不需要在系统中存储“密码“ 缺点:编码/译码，或者说加密/解密要花费一定时间 访问控制 在每个文件的FCB (或索引结点)中增加一个访问控制列表(Access-Control List, ACL)，该表中记录了各个用户可以对该文件执行哪些操作。 精简的访问列表:以“组”为单位，标记各“组”用户可以对文件执行哪些操作。如:分为系统管理员、文件主、文件主的伙伴、其他用户几个分组。 当某用户想要访问文件时，系统会检查该用户所属的分组是否有相应的访问权限。（系统需要管理分组的信息） Windows的访问控制 总结： 文件系统的层次结构 磁盘的结构","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://amourlover.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统第三章","slug":"操作系统第三章","date":"2020-05-30T06:54:02.000Z","updated":"2020-06-12T15:32:14.590Z","comments":true,"path":"2020/05/30/操作系统第三章/","link":"","permalink":"http://amourlover.xyz/2020/05/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E7%AB%A0/","excerpt":"内存、分页分段","text":"内存、分页分段 内存的基础知识 什么是内存，有什么作用 内存是用于存放数据的硬件。程序执行前需要先放到内存中才能被CPU处理。 常用的数量单位 进程的运行原理——指令 可见，我们写的代码要翻译成CPU能识别的指令。这些指令会告诉CPU应该去内存的哪个地址存/取数据,这个数据应该做什么样的处理。在这个例子中，指令中直接给出了变量x的实际存放地址(物理地址)。但实际在生成机器指令的时候并不知道该进程的数据会被放到什么位置。所以编译生成的指令中–般是使用逻辑地址(相对地址)。 逻辑地址vs物理地址 住酒店时酒店给你们安排了4个房号相连的房间。四个人按学号递增次序入住房间。比如0、1、2、3号同学分别入住了5、6、7、8号房间。 四个人的编号0、1、2、3其实是一个“相对位置”，而各自入住的房间号是一个“绝对位置”。 只要知道0号同学住的是房号为N的房间，那么M号同学的房号一定是N+M。 也就是说，只要知道各个同学的“相对位置”和“起始房号”，就一定可以算出所有同学的“绝对位置“ 从写程序到程序运行 编译:由编译程序将用户源代码编译成若干个目标模块(编译就是把高级语言翻译为机器语言) 链接:由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块 装入(装载) :由装入程序将装入模块装入内存运行 装入板块装入内存 装入的三种方式(用三种不同的方法完成逻辑地址到物理地址的转换); 绝对装入 静态重定位 动态重定位 绝对装入 绝对装入:在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存。 绝对装入只适用于单道程序环境。 程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。通常情况下都是编译或汇编时再转换为绝对地址。 静态重定位 静态重定位:又称可重定位装入。编译、链接后的装入模块的地址:都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行“重定位”，将逻辑地址变换为物理地址(地址变换是在装入时一次完成的)。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。作业一旦进入内存后， 在运行期间就不能再移动，也不能再申请内存空间。 动态重定位 动态重定位:又称动态运行时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方式需要-一个重定位寄存器的支持。 采用动态重定位时允许程序在内存中发生移动。 并且可将程序分配到不连续的存储区中:在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存:便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 链接的三种方式 链接的三种方式: 静态链接:在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件(装入模块)之后不再拆开。 装入时动态链接:将各目标模块装入内存时，边装入边链接的链接方式。 运行时动态链接:在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存管理的概念 内存空间的分配与回收 操作系统作为系统资源的管理者，当然也需要对内存进行管理，要管些什么呢? 1.操作系统负责内存空间的分配与回收 2.操作系统需要提供某种技术从逻辑上对内存空间进行扩充 3.操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换（过程称为地址重定位） 4.内存保护：操作系统需要提供内存保护功能。保证各进程在各自存储空间内 内存保护可采取两种方法: 方法一:在CPU中设置一对上、下限寄存器，存放进程的上、下限地址。 进程的指令要访问某个地址时，CPU检查是否越界。 方法二:采用重定位寄存器(又称基址寄存器)和界地址寄存器(又称限长寄存器)进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。 覆盖与交换 覆盖技术 早期的计算机内存很小，比如IBM推出的第一台PC机最大只支持1MB大小的内存。因此经常会出现内存大小不够的情况。 后来人们引入了覆盖技术，用来解决“程序大小超过物理内存总和”的问题 覆盖技术的思想:将程序分为多个段(多个模块)。常用的段常驻内存，不常用的段在需要时调入内存。内存中分为-一个“固定区”和若干个“覆盖区”。 需要常驻内存的段放在“固定区”中，调入后就不再调出(除非运行结束)。不常用的段放在“覆盖区，需要用到时调入内存, 用不到时调出内存。 必须由程序员声明覆盖结构，操作系统完成自动覆盖。缺点:对用户不透明，增加了用户编程负担。 覆盖技术只用于早期的操作系统中，现在已成为历史。 交换技术 交换(对换)技术的设计思想:内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度) 应该在外存(磁盘)的什么位置保存被换出的进程? 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。 什么时候应该交换? 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如:在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一-些进程;如果缺页率明显下降，就可以暂停换出。 应该换出哪些进程? 可优先换出阻塞进程;可换出优先级低的进程;为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间… （注意：PCB会常驻内存，不会被换出外存） 连续分配管理方式 连续分配：指为用户进程分配的必须是一个连续的内存空间。 单一连续分配 在单一连续分配方式中，内存被分为系统区和用户区。 系统区通常位于内存的低地址部分，用于存放操作系统相关数据;用户区用于存放用户进程相关数据。内存中只能有一道用户程序，用户程序独占整个用户区空间。 优点:实现简单;无外部碎片;可以采用覆盖技术扩充内存;不一定需要采取内存保护(eg:早期的PC操作系统MS-DOS)。 缺点:只能用于单用户、单任务的操作系统中;有内部碎片;存储器利用率极低。 内部碎片:分配给某进程的内存区域中，如果有些部分没有用上，就是“内部碎片”。 固定分区分配 20世纪60年代出现了支持多道程序的系统，为了能在内存中装入多道程序，且这些程序之间又不会相互干扰，于是将整个用户空间划分为若千个固定大小的分区，在每个分区中只装入一道作业，这样就形成了最早的、最简单的一种可运行多道程序的内存管理方式。 分区大小相等:缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合(比如:钢铁厂有n个相同的炼钢炉，就可把内存分为n个大小相等的区域存放n个炼钢炉控制程序) 分区大小不等:增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分(比如:划分多个小分区、适量中等分区、少量大分区) 操作系统需要建立一个数据结构——分区说明表，来实现各个分区的分配与回收。每个表项对应一一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态(是否已分配)。 当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表，从中找到一个能满足大小的、未分配的分区，将之分配给该程序，然后修改状态为“已分配’ 优点:实现简单，无外部碎片。 缺点: a. 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能; b. 会产生内部碎片，内存利用率低。 动态分区分配 动态分区分配又称为可变分区分配。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的。(eg: 假设某计算机内存大小为64MB，系统区8MB，用户区共56 M…) 系统要有什么样的数据结构记录内存的使用情况？ 当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？ 如何进行分区的分配与回收操作? 假设系统采用的数据结构是“空闲分区表”如何分配? 这个分为几种不同情况比较容易理解，不放截图了，放了我也看不懂。 动态分区分配没有内部碎片，但是有外部碎片。 内部碎片，分配给某进程的内存区域中，如果有些部分没有用上。 外部碎片，是指内存中的某些空闲分区由于太小而难以利用。 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。可以通过紧凑(拼凑，Compaction) 技术来解决外部碎片。 动态分区分配算法 知识总览 动态分区分配算法:在动态分区分配方式中，当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配? 算法 首次适应算法（First Fit） 算法思想:每次都从低地址开始查找，找到第一个能满足大小的空闲分区。 如何实现:空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 最佳适应算法（Best Fit） 算法思想:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。 如何实现:空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链( 或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 缺点:每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片。 最坏适应算法（Wrost Fit） 又称最大适应算法(Largest Fit) 算法思想:为了解决最佳适应算法的问题–即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。 如何实现:空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。 缺点:每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了。 邻近适应算法（Next Fit） 算法思想:首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。 如何实现:空闲分区以地址递增的顺序排列(可排成一一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第- - 个空闲分区。 首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会更有可能把高地址部分的大分区保留下来(最佳适应算法的优点) 邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用(最大适应算法的缺点) 综合来看，四种算法中，首次适应算法的效果反而更好 分页 基本分页存储管理的基本概念 连续分配：为用户进程分配的必须是一个连续的内存空间。 非连续分配：为用户进程分配的可以是一些分散的内存空间。 把“固定分区分配”改在为“非连续分配版本” 假设进程A大小为23MB，但是每个分区大小只有10MB，如果进程只能占用一个分区，那显然放不下。解决思路:如果允许进程占用多个分区，那么可以把进程拆分成10MB+10MB+3MB三个部分，再把这三个部分分别放到三个分区中(这些分区不要求连续) .. 进程A的最后一个部分是3MB，放入分区后会产生7MB的内部碎片。如果每个分区大小为2MB，那么进程A可以拆分成11 * 2MB +1MB共12个部分，只有最后一部分1MB占不满分区，会产生1MB的内部碎片。显然，如果把分区大小设置的更小一些，内部碎片会更小，内存利用率会更高。 基本分页存储管理的思想一把内存分为一个个相等的小分区，再按照分区大小把进程拆分成一个个小部分。 分页存储管理的基本概念 将内存空间分为一个个大小相等的分区(比如:每个分区4KB) ,每个分区就是一个“页框”，或称“页帧“、“内存块”、 “物理块”。每个页框有一个编号，即“页框号“（“或者内存块号”、”页帧号”、“物理块号”)页框号从0开始。 将用户进程的地址空间也分为与页框大小相等的一一个个区域，称为“页”或“页面。每个页面也有一个编号，即“页号’，页号也是从0开始。 (注:进程的最后一个页面可能没有一个页框那么大。因此，页框不能太大，否则可能产生过大的内部碎片) 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中。 如何实现逻辑地址到物理地址的转换 逻辑地址结构 分页存储管理的逻辑地址结构如下所示: 地址结构包含两个部分:前一部分为页号，后一部分为页内偏移量W。在上图所示的例子中，地址长度为32位，其中011位为“页内偏移量”，或称“页内地址”; 1231位为“页号”。 如果有K位表示“页内偏移量”，则说明该系统中一个页面的大小是2K个内存单元如果有M位表示“页号”，则说明在该系统中，一个进程最多允许有2M个页面 分页存储管理中，如何实现地址转换? 要算出逻辑地址对应的页号 要知道该页号对应页面在内存中的起始地址 要算出逻辑地址在页面内的“偏移量” 物理地址=页面始址+页内偏移量 页表 总结 基本地址变换机构 基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。通常会在系统中设置-一个页表寄存器(PTR)，存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块(PCB)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。 注意:页面大小是2的整数幂 设页面大小为，逻辑地址A到物理地址E的变换过程如下: 例题： 在分页存储管理( 页式管理)的系统中，只要确定了每个页面的大小，逻辑地址结构就确定了。因此，页式管理中地址是一维的。即，只要给出一个逻辑地址，系统就可以自动地算出页号、页内偏移量两个部分，并不需要显式地告诉系统这个逻辑地址中，页内偏移量占多少位。 对各表项大小的进一步探索 总结 具有快表的地址变换机构 局部性原理 什么是快表（TLB） 快表，又称联想寄存器(TLB) ，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。 两级页表 单级页表存在的问题 如何解决单级页表的问题？ 问题一:页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。 问题二:没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。 可将长长的页表进行分组，使每个内存块刚好可以放入一一个分组(比如上个例子中，页面大小4KB,每个页表项4B，每个页面可存放1K个页表项，因此每1K个连续的页表项为- -组，每组刚好占一个内存块，再讲各组离散地放到各个内存块中) 另外，要为离散分配的页表再建立一张页表，称为页目录表,或称外层页表，或称顶层页表. 两级页表的原理、地址结构 如何实现地址的变换 注意！ 若采用多级页表机制，则各级页表的大小不能超过一个页面 两级页表的访存次数分析(假设没有快表机构) 第一次访存:访问内存中的项目录表 第二次访存:访问内存中的二级页表， 第三次访存:访问目标内存单元 总结： 分段部分 基本分段存储管理方式 分段 进程的地址空间:按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名(在低级语言中，程序员使用段名来编程)，每段从0开始编址内存分配规则:以段为单位进行分配，每个段在内存中占据连续空间，但各段之，间可以不相邻。 分段系统的逻辑地址结构由段号(段名)和段内地址(段内偏移量)所组成。如: 段表 问题:程序分多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需为每个进程建立一张段映射表，简称“段表” 地址变换 分段、分页管理的对比 页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理.上的需要，完全是系统行为，对用户是不可见的。 段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一-组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。 页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。 分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。 分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。 分段比分页更容易实现信息的共享和保护。 不能被修改的代码称为纯代码或可重入代码(不属于临界资源)，这样的代码是可以共享的。可修改的代码是不能共享的(比如，有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致) 段页式管理方式 分页、分段的优缺点分析 分段管理中产生的外部碎片也可以用“紧凑”来解决，只是分段管理中产生的外部碎片也可以用“紧凑”来解决，只是需要付出较大的时间代价 分页+分段=段页式管理 段页式管理的逻辑地址结构 分段系统的逻辑地址结构由段号和段内地址(段内偏移量)组成。如: 段页式系统的逻辑地址结构由段号、页号、页内地址(页内偏移量)组成。如: “分段”对用户是可见的，程序员编程时需要显式地给出段号、段内地址。而将各段“分页”对用户是不可见的。系统会根据段内地址自动划分页号和页内偏移量。因此段页式管理的地址结构是二维的。 段表、页表 总结 虚拟内存的基本概念 传统存储管理方式的特征、特点 一次性:作业必须一.次性全部装入内存后才能开始运行。这会造成两个问题:①作业很大时，不能全部装入内存，导致大作业无法运行;②当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。 驻留性:一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的–小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。 局部性原理 时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环) 空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的) 虚拟内存的定义和特征 虚拟内存有一下三个主要特征: 多次性:无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。 对换性:在作业运行时无需–直常驻内存，而是允许在作业运行过程中，将作业换入、换出。 虚拟性:从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。 如何实现虚拟内存技术 虚拟内存技术，允许-一个作业分多次调入内存。如果采用连续分配方式，会不方便实现。因此, 虚拟内存的实现需要建立在离散分配的内存管理方式基础上。 主要区别: 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。（操作系统要提供请求调页（或请求调段）功能） 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。（操作系统要提供页面置换（或段置换）的功能） 总结 请求分页管理方式 请求分页存储管理与基本分页存储管理的主要区别: 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。（操作系统要提供请求调页功能，将缺失页面从外存调入内存） 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。（操作系统要提供页面置换的功能，将暂时用不到的页面换出外村） 页表机制 与基本分页管理相比，请求分负管理中，为了实现“请求调页”，操作系统需要知道每个页面是否已经调入内存:如果还没调入，那么也需要知道该页面在外存中存放的位置。 当内存空间不够时，要实现“页面置换”，操作系统需要通过某些指标来决定到底换出哪个页面;有的页面没有被修改过，就不用再浪费时间写回外存。有的页面修改过，就需要将外存中的旧数据覆盖，因此，操作系统也需要记录各个页面是否被修改的信息。 缺页中断机构 在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断。 此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。如果内存中有空闲块，则为进程分配-一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。 如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。未修改过的页面不用写回外存。 缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断。 一.条指令在执行期间，可能产生多次缺页中断。(如: copyAto B，即将逻辑地址A中的数据复制到逻辑地址B，而A、B属于不同的页面，则有可能产生两次中断) 地址变换机构 在具有快表机构的请求分页系统中，访问一个逻辑地址时，若发生缺页，则地址变换步骤是: 查快表(未命中)–查慢表(发现未调入内存)–调页(调入的页面对应的表项会直接加入快表)–查快表(命中)–访问目标内存单元 总结： 页面置换算法！！ 最佳置换算法（OPT） 最佳置换算法(OPT，Optimal) :每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。 最佳置换算法(OPT, Optimal) :每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。 最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。 先进先出置换算法（FIFO） 先进先出置换算法(FIFO) :每次选择淘汰的页面是最早进入内存的页面 实现方法:把调入内存的页面根据调入的先后顺序排成–个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块。 Belady异常—— 当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。 只有FIFO算法会产生Belady 异常。另外，FIFO算法 虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差。 最近最久未使用置换算法（LRU） 最近最久未使用置换算法(LRU， least recently used) :每次淘汰的页面是最近最久未使用的页面实现方法:赋予每个页面对应的页表项中，用访间字段记录该页面自.上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。 该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大。 时钟置换算法（CLOCK） 最佳置换算法性能最好，但无法实现;先进先出置换算法实现简单，但算法性能差;最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门门的硬件支持，算法开销大。 时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法(NRU，Not Recently Used ) 简单的CLOCK算法实现方法:为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出;如果是1， 则将它置为0，暂不换出，继续检查下一个页面，若第- -轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描(第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描) 改进型的时钟置换算法 简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过,就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。 因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/0操作。这就是改进型的时钟置换算法的思想。 修改位=0，表示页面没有被修改过;修改位=1， 表示页面被修改过。 为方便讨论，用(访问位，修改位)的形式表示各页面状态。如(1，1)表示一个页面近期被访问过,且被修改过。 算法规则:将所有可能被置换的页面排成一个循环队列 第一轮:从当前位置开始扫描到第-一个(0,0) 的帧用于替换。本轮扫描不修改任何标志位。（第一优先级:最近没访问，且没修改的页面） 第二轮:若第-轮扫描失败，则重新扫描，查找第-一个(0, 1)的帧用于替换。本轮将所有扫描过的帧访问位设为0。（第二优先级:最近没访问，但修改过的页面） 第三轮:若第二轮扫描失败，则重新扫描，查找第一个(0,0) 的帧用于替换。本轮扫描不修改任何标志位。（第三优先级:最近访问过，但没修改的页面） 第四轮:若第三轮扫描失败，则重新扫描，查找第一个(0, 1)的帧用于替换。（第四优先级:最近访问过，且修改过的页面） 由于第二轮已将所有帧的访问位设为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型CLOCK置换算法选择一个淘汰页面最多会进行四轮扫描 总结： 页面分配策略 页面分配、置换策略 驻留集:指请求分页存储管理中给进程分配的物理块的集合。 在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少;驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择- - 个合适的驻留集大小。 固定分配:操作系统为每个进程分配一-组固定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变 可变分配:先为每个进程分配一定数 目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即，驻留集大小可变. 局部置换:发生缺页时只能选进程自己的物理块进行置换。 全局置换:可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。 固定分配局部置换:系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一-页换出，然后再调入需要的页面。这种策略的缺点是:很难在刚开始就确定应为每个进程分配多少个物理块才算合理。(采用这 种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为- - 个进程分配的内存块数) 可变分配全局置换:刚开始会为每个进程分配一定数量的物理块。操作系统会保持- - 个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一-块分配给该进程;若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。采用这种策略时，只要某进程发生缺页,都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。 可变分配局部置换:刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度;反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。 可变分配全局置换:只要缺页就给分配新物理块 可变分配局部置换:要根据发生缺页的频率来动态地增加或减少进程的物理块 何时调入页面 预调页策略:根据局部性原理，一次调入若干个相邻的页面可能比一次调入-一个页面更高效。但如果提前调入的页面中大多数都没被访问过，则又是低效的。因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。故这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分。（运行前调入） 局部性原理：主要指空间局部性，即:如果当前访问了某个内存单元，在之后很有可能会接着访问与其相邻的那些内存单元。 请求调页策略:进程在运行期间发现缺页时才将所缺页面调入内存。由这种策略调入的页面一-定会被访问到，但由于每次只能调入一-页，而每次调页都要磁盘I/O操作，因此I/0开销较大。（运行时调入） 从何处调入页面 系统拥有足够的对换区空间:页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区。 系统缺少足够的对换区空间:凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。 UNIX方式:运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。 抖动（颠簸）现象 刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够) 为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率。 工作集 驻留集:指请求分页存储管理中给进程分配的物理块的集合。 工作集:指在某段时间间隔里，进程实际访问页面的集合。 工作集大小可能小于窗口尺寸，实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块。如:窗口尺寸为5，经过一-段时间的监测发现某进程的工作集最大为3，那么说明该进程有很好的局部性，可以给这个进程分配3个以上的内存块即可满足进程的运行需要。 一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页。 拓展：基于局部性原理可知，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的。 总结：","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://amourlover.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统第二章","slug":"操作系统第二章","date":"2020-05-26T09:10:06.000Z","updated":"2020-05-30T14:16:20.000Z","comments":true,"path":"2020/05/26/操作系统第二章/","link":"","permalink":"http://amourlover.xyz/2020/05/26/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E7%AB%A0/","excerpt":"进程、一些算法、信号量、问题、死锁","text":"进程、一些算法、信号量、问题、死锁 进程的定义、组成、组织方式… 进程的定义 程序：就是一个指令序列。 早期的计算机（只支持单道程序），CPU、I/O设备、内存都为一道程序服务。 内存（程序段（低地址），数据段（高地址））：程序的代码放在程序段内，程序运行过程处理的数据放在数据段内。 引入多道程序后： 为了方便操作系统管理，完成各程序并发执行，引入了进程、进程实体的概念。 PCB:系统为每个运行的程序配置一个数据结构，称为进程控制块（PCB），用来描述进程的各种信息（如程序代码存放位置）。操作系统通过PCB来管理进程，因此PCB中应该包含操作系统对其进行管理所需的各种信息。 PCB、程序段、数据段三部分构成了进程实体（进程映像）。一般情况下，我们把进程实体就简称为进程，例如，所谓创建进程，实质上是创建进程实体中的PCB；而撤销进程，实质上是撤销进程实体中的PCB。注意：PCB是进程存在的唯一标准！ 从不同的角度，进程可以有不同的定义，比较传统典型的定义有：强调“动态性” 1、进程是程序的一次执行过程。 2、进程是一个程序及其数据在处理机上顺序执行时所发生的活动。 3、进程时具有独立功能的程序在数据集合上运动的过程，它是系统进行资源分配和调度的一个独立单位。 引入进程实体的概念后，可把进程定义为：进程时进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。 注意：严格来说，进程实体和进程并不一样，进程实体是静态的，进程则是动态的。不过，除非题目专门考察二者的区别，否则可以认为进程实体就是进程。因此我们也可以说“进程由程序段、数据段、PCB三部分组成”。 进程的组成 进程的组织 在一个系统中，通常有数十、数百乃至数千个PCB。为了能对他们加以有效的管理，应该用适当的方式把这些PCB组织起来。 注：进程的组成讨论的是一个进程内部由哪些部分构成的问题，而进程的组织讨论的是多个进程之间的组织方式问题。 进程的特征 进程和程序是两个截然不同的概念，相比于程序，进程拥有以下特征: 进程的状态与转换 状态 进程的三种基本状态： 运行态（Running）：占有CPU，并在CPU上运行。（注意：单核处理机环境下，每一时刻最多只有一个进程处于运行态。（双核环境下可以同时有两个进程处于运行态））。 就绪态（Ready）：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行（进程已经拥有了除处理机之外所以需要的资源，一旦获得处理机，即可立即进入运行态开始运行。即;万事具备，只欠CPU）。 阻塞态（Waiting/Blocked,又称：等待态）：因等待某一事件而暂时不能运行（如：等待操作系统分配打印机、等待读磁盘操作的结果。CPU是计算机中最昂贵的部件，为了提高CPU的利用率，需要先将其他进程需要的资源分配到位，才能得到CPU的服务）。 另外两种状态： 创建态（New，又称：新建态）：进程正在被创建，操作系统为进程分配资源、初始化PCB。 终止态（Terminated，又称：结束态）：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。 进程状态的转换 注意：不能由阻塞态直接转换为运行态，也不能由就绪态直接转换为阻塞态（因为进入阻塞态是进程主动请求的，必然需要进程在运行时才能发出这种请求） 进程控制 基本概念 什么是进程控制？ 进程控制的主要功能是对系统中的所以进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。 简化理解：反正进程控制就是实现进程状态转换。 如何实现进程控制？ 用原语实现进程控制。原语的特点是执行期间不允许中段，只能一气呵成。这种不可被中断的操作即原子操作。原语采用“关中断指令”和“开中断指令”实现 显然，关/开中断指令的权限非常大，必然是只允许在核心态下执行的特权指令。 进程控制相关的原语 学习技巧:进程控制会导致进程状态的转换。无论哪个原语，要做的无非三类事情: 更新PCB中 的信息(如修改进程状态标志、将运行环境保存到PCB、从PCB恢复运行环境) a.所有的进程控制原语—定都会修改进程状态标志 b.剥夺当前运行进程的CPU使用权必然需要保存其运行环境 c.某进程开始运行前必然要恢复期运行环境 将PCB插入 合适的队列 分配/回收资源 进程通信 什么是进程通信 进程通信就是指进程之间的信息交换。 进程是分配稀土资源的单位（包括内存地址空间），因此个金拥有的内存地址空间相互独立。 为了保证安全，一个进程不能直接访问另外一个进程的地址空间。但是进程之间的信息交换又是必须实现的。为了保证进程间的安全通信操纵系统提供了一些方法。 进程通信：1、共享存储。2、消息传递。3、管道通信。 共享存储 操作系统只负责提供共享空间和同步互斥工具（如P、V操作）。两个进程对共享空间的访问必须是互斥的（互斥访问通过操作系统提供的工具实现）。 共享存储：1、基于数据结构的共享（比如共享空间里只能放一个长度是10的数组。这种存储方式速度慢、限制多。是一种低级通信方式）。2、基于存储区的共享（在内存中划出一块共享存储区、数据的形式、存放位置都由进程控制，而不是操纵系统：相比之下，这种共享方式速度更快，是一种高级通信方式）。 管道通信 ”管道“是指用于连接读写进程的一个共享文件，又名pipe文件。其实就是在内存中开辟一个大小固定的缓冲区。 管道只能采用半双工通信，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道。 各进程要互斥地访问管道。 数据以字符流的形式写入管道，当管道写满时，写进程的write()系统调用将被阻塞，等待读进程将数据取走。当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。 如果没写满，就不允许读。如果没读空，就不允许写。 数据一旦被读出，就从管道中被拋弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情况。 消息传递 进程间的数据交换以格式化的消息（Message）为单位。进程通过操作系统提供的”发送消息/接受消息”连哥哥原语进行数据交换。 Message：1、消息头（包括：发送进程ID、接受进程ID、消息类型、消息长度等格式化的信息（计算机网络中发送的”报文”其实就是一种格式化的消息））2、消息体 消息传递：1、直接通信方式（消息直接挂到接受进程的消息缓冲队列上）2、间接通信方式（消息要先发送到中间实体（信箱）中，因此也称“信箱通信方式”。Eg:计网中的电子邮件系统） 线程概念和多线程模型 什么是线程，为什么引入线程？ 还没引入线程之前，系统中各个程序只能串行执行地执行一系列程序。为此，引入了“线程”，来增加开发度。传统的进程是程序执行流的最小单位。 引入线程后，线程成为了程序执行流的最小单位。是一个基本的CPU执行单元。可以把线程理解为“轻量级进程”。不仅是进程之间可以并发，进程内的各线程之间也可以并发，进程内的各线程之间也可以并发，从而进一步提高了系统的并发度，使得一个进程内也可以并发处理各种任务（如QQ视频、文字聊天、传文件）。 引入线程后，进程只作为除CPU之外的系统资源的分配单元（如打印机、内存地址空间等都是分配给进程的）。 引入线程机制后，有什么变化？ 线程的属性 线程的实现方式 用户级线程（ULT） 用户级线程由应用程序通过线程库实现。所有的线程管理工作都由应用程序负责（包括线程切换） 用户级线程中，线程切换可以在用户态下即可完成，无需操作系统干预。 在用户看来，是有多个线程。但是操作系统内核看来，并意识不到线程的存在。（用户级线程对用户不透明，对操作系统透明） 可以这样理解，“用户级线程”就是“从用户视角看能看到的线程” 内核级线程（KLT 又称为“内核支持的线程”） 内核级线程的管理工作由操作系统内核完成。线程调度、切换等工作都由内核负责，因此，内核级线程的切换必须在核心态下才能完成。 可以这样理解，“内核级线程”就是“从操作系统内核视角看能看到的线程” 在同时支持用户级线程个内核级线程的系统中,可采用两者组合的方式：将n个用户级线程映射到m个内核级线程上（n&gt;=m） 注意：操作系统只能“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位。 多线程模型 在同时支持用户级线程个内核级线程的系统中，由几个用户级线程映射到几个内核级线程的问题引出了“多线程模型”问题。 多对一模型：多个用户及线程映射到一个内核级线程。每个用户进程只对应一个内核级线程。 优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高。 缺点：当一个用户级程序被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并发执行。 一对一模型：一个用户级线程映射到一个内核级线程。每个用户进程有于用户级线程同数量的内核级线程。 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理机上并行执行。 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高、开销大。 多对多模型：n用户级线程映射到m个内核级线程（n&gt;m）。每个用户进程对应m个内核级线程。 克服了多对一模型并发度不高的缺点，有克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。 处理机调度的概念、层次 调度的基本概念 当有一堆任务要处理，但由于资源有限，这些事情没法同时处理，这就需要某种规则来决定处理这些任务的顺序，这就是“调度”研究的问题。 在多道程序系统中，进程的数量往往时多余处理机的个数的，这样不可能同时并行地处理各个进程。 处理机调度，就是从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行，以实现进程的并发执行。 调度的三个层次——高级调度 由于内存空间有限，有时无法将用户提交的作业全部放入内存，因此就需要确定某种规则来决定将作业调入内存的顺序。 高级调度（作业调度）。按一定的原则从外存上处于后备队列的作业中挑选一个（或多个）作业，给他们分配内存等必要资源，并建立相应的进程（建立PCB），以使它（们）获得竞争处理机的权利。 高级调度是辅存(外存)与内存之间的调度。每个作业只调入一次，调出一次。作业调入时会建立相应的PCB，作业调出时才撤销PCB。高级调度主要是指调入的问题，因为只有调入的时机需要操作系统来确定，但调出的时机必然是作业运行结束才调出。 调度的三个层次——中级调度 引入了虚拟存储技术之后，可将暂时不能运行的进程调至外存等待。等它重新具备了运行条件且内存又稍有空闲时，再重新调入内存。这么做的目的是为了提高内存利用率和系统吞吐量。暂时调到外存等待的进程状态为挂起状态。值得注意的是，PCB并不会一起调到外存，而是会常驻内存。PCB中会记录进程数据在外存中的存放位置，进程状态等信息，操作系统通过内存中的PCB ,来保持对各个进程的监控、管理。被挂起的进程PCB会被放到的挂起队列中。 中级调度(内存调度)，就是要决定将哪个处于挂起状态的进程重新调入内存。一个进程可能会被多次调出、调入内存，因此中级调度发生的频率要比高级调度更高。 调度的三个层次——低级调度 低级调度(进程调度)，其主要任务是按照某种方法和策略从就绪队列中选取一一个进程，将处理机分配给它。 进程调度是操作系统中最基本的一种调度，在–般的操作系统中都必须配置进程调度。进程调度的频率很高，一般几十毫秒一次。 三层调度的联系、对比 进程调度相关知识 时机 进程调度（低级调度），就是按照某种算法从就绪队列中选择一个进程为其分配处理机。 进程在操作系统内核程序临界区中不能进行调度与切换，但是在普通临界区中是可以进行调度、切换的。 临界资源:一个时间段内只允许–个进程使用的资源。各进程需要互斥地访问临界资源。 临界区:访问临界资源的那段代码。 内核程序临界区：一般是用来访问某种内核数据结构的，比如进程的就绪队列(由各就绪进程的PCB组成) 方式 非剥夺调度方式：又称非抢占方式。即，只允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。 实现简单，系统开销小但是无法及时处理紧急任务，适合于早期的批处理系统 剥夺调度方式，又称抢占方式。当一个进程正在处理机上执行时，如果有-一个更重要或更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程。 可以优先处理更紧急的进程，也可实现让各进程按时间片轮流执行的功能(通过时钟中断)。适合于分时操作系统、实时操作系统。 进程的切换与过程 “狭义的进程调度”与“进程切换”的区别: 狭义的进程调度指的是从就绪队列中选中-一个要运行的进程。(这个进程可以是刚刚被暂停执行的进程，也可能是另一个进程，后- -种情况就需要进程切换) 进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。 广义的进程调度包含了选择一个进程和进程切换两个步骤。 进程切换的过程主要完成了: 对原来运行进程各种数据的保存 对新的进程各种数据的恢复 (如:程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在进程控制块) 注意:进程切换是有代价的，因此如果过于频繁的进行进程调度、切换，必然会使整个系统的效率降低,使系统大部分时间都花在了进程切换上，而真正用于执行进程的时间减少。 调度算法的评价标准 CPU利用率 由于早期的CPU造价极其昂贵，因此人们会希望让CPU尽可能多地工作。 CPU利用率:指CPU“忙碌”的时间占总时间的比例。 CPU利用率=忙碌的时间/总时间 系统吞吐量 对于计算机来说，希望能用尽可能少的时间处理完尽可能多的作业 系统吞吐量:单位时间内完成作业的数量 系统吞吐量=总共完成了多少道作业/总共花了多少时间 周转时间 等待时间 响应时间 对于计算机用户来说，会希望自己的提交的请求(比如通过键盘输入了一个调试命令)尽早地开始被系统服务、回应。 响应时间，指从用户提交请求到首次产生响应所用的时间。 FCFS、SJF、HRRN调度算法 先来先服务FCFS 短作业优先SJF 高相应比优先 时间片轮转、优先级、多级反馈队列 时间片轮转调度算法RR 优先级调度算法 多级反馈队列调度算法 进程同步与进程互斥 我们把一个时间段内只允许一个进程使用的资源称为临界资源。许多物理设备(比如摄像头、打印机)都属于临界资源。此外还有许多变量、数据、内存缓冲区等都属于临界资源。对临界资源的访问，必须互斥地进行。互斥，亦称间接制约关系。进程互斥指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问临界资源。 进程互斥的软件实现方法 单标志法 双标志先检查法 双标志后检查法 Peterson算法 进程互斥的硬件实现方法 中断屏蔽方法 利用“开/关中断指令”实现(与原语的实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况) 优点:简单、高效缺点:不适用于多处理机;只适用于操作系统内核进程，不适用于用户进程(因为开/关中断指令只能运行在内核态，这组指令如果能让用户随意使用会很危险)只能运行在内核态，这组指令如果能让用户随意使用会很危险) TestAndSet指令 简称TS指令，也有地方称为TestAndSetLock指令，或TSL指令 TSL指令是用硬件实现的，执行的过程不允许被中断，只能一 -气呵成。以下是用C语言描述的逻辑 若刚开始lock是false, 则TSL返回的old值为false, while 循环条件不满足，直接跳过循环，进入临界区。若刚开始lock是true，则执行TLS后old返回的值为true，while 循环条件满足，会一直循环，直到当前访问临界区的进程在退出区进行“解锁”。相比软件实现方法，TSL 指令把“上锁”和“检查”操作用硬件的方式变成了一气呵成的原子操作。 优点:实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞;适用于多处理机环境。 缺点:不满足“让权等待”原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”。 Swap指令 有的地方也叫Exchange指令，或简称XCHG指令。 Swap指令是用硬件实现的，执行的过程不允许被中断，只能–气呵成。以下是用C语言描述的逻辑 逻辑.上来看Swap和TSL并无太大区别，都是先记录下此时临界区是否已经被上锁(记录在old变量上)，再将上锁标记lock设置为true，最后检查old，如果old为false则说明之前没有别的进程对临界区_上锁，则可跳出循环，进入临界区。 优点:实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞;适用于多处理机环境。 缺点:不满足“让权等待”原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”。 信号量机制 用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥、进程同步。 信号量其实就是一个变量(可以是- 一个整数，也可以是更复杂的记录型变量)，可以用一个信号量来表示系统中某种资源的数量，比如:系统中只有一台打印机，就可以设置一个初值为1的信号量。 原语是一种特殊的程序段，其执行只能一气呵成，不可被中断。原语是由关中断/开中断指令实现的。软件解决方案的主要问题是由“进入区的各种操作无法一气呵成”，因此如果能把进入区、退出区的操作都用“原语”实现，使这些操作能“一气呵成”就能避免问题。 一对原语:wait(S)原语和signal(S)原语，可以把原语理解为我们自己写的函数，函数名分别为wait和signal,括号里的信号量S其实就是函数调用时传入的-一个参数。 wait、signal 原语常简称为P、V操作(来自荷兰语proberen和verhogen)。因此，做题的时候常把wait(S)、signal(S) 两个操作分别写为P(S)、V(S) 信号量机制——整型信号量 用一个整数型的变量作为信号量，用来表示系统中某种资源的数量。（与普通整数变量的区别:对信号量的操作只有三种，即初始化、P操作、V操作） 信号量机制——记录型信号量 整型信号量的缺陷是存在“忙等”问题，因此人们又提出了“记录型信号量”，即用记录型数据结构表示的信号量。 用信号量机制实现进程互斥、同步、前驱关系 信号量机制实现进程互斥 1.分析并发进程的关键活动，划定临界区(如:对临界资源打印机的访问就应放在临界区) 2.设置互斥信号量mutex,初值为1. 3.在临界区之前执行P(mutex) 4.在临界区之后执行V(mutex) 注意:对不同的临界资源需要设置不同的互斥信号量。P、V操作必须成对出现。缺少P(mutex)就不能保证临界资源斥访问。缺少V(mutex)会导致资源的互永不被释放，等待进程永不被唤醒。 信号量机制实现进程同步 用信号量实现进程同步: 1.分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作( 或两句代码) 2.设置同步信号量S, 初始为0 3.在“前操作”之后执行V(S) 4.在“后操作”之前执行P(S) 若先执行到V(S)操作，则S++ 后S=1。之后当执行到P(S)操作时，由于S=1，表示有可用资源，会执行S–，S的值变回0,P2进程不会执行block原语，而是继续往下执行代码4。 若先执行到P(S)操作，由于S=0，S– 后S=-1，表示此时没有可用资源，因此P操作中会执行block原语，主动请求阻塞。之后当执行完代码2，继而执行V(S)操作，S++， 使S变回0,由于此时有进程在该信号量对应的阻塞队列中，因此会在V操作中执行wakeup原语，唤醒P2进程。这样P2就可以继续执行代码4了。 信号量机制实现前驱关系 进程P1中有句代码S1，P2中有句代码S2….P6中有句代码S6。这些代码要求按如下前驱图所示的顺序来执行: 其实每一对前驱关系都是一个进程同步问题(需要保证一前一后的操作)，因从： 1.要为每一对前驱关系各设置-一个同步变量 2.在“前操作”之后对相应的同步变量执行V操作 在“后操作”之前对相应的同步变量执行P操作 生产者消费者问题 问题描述 系统中有一组生产者进程和一-组消费者进程，生产者进程每次生产-一个产品放入缓冲区，消费者进程每次从缓冲区中取出一一个产品并使用。(注: 这里的“产品”理解为某种数据)生产者、消费者共享-一个初始为空、大小为n的缓冲区。 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待。 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待。 缓冲区是临界资源，各进程必须互斥地访问。 PV操作题目分析步骤: 1.关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。 2.整理思路。根据各进程的操作流程确定P、V操作的大致顺序。 3.设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。 (互斥信号量初值一般为1，同步信号里的初如值要看对应资源的初如值足多少) P、V操作是否可以交换问题 生产者消费者问题是一个互斥、同步的综合问题。对于初学者来说最难的是发现题目中隐含的两对同步关系。有时候是消费者需要等待生产者生产，有时候是生产者要等待消费者消费，这是两个不同的“一前一后问题”，因此也需要设置两个同步信号量。 多生产者多消费者问题 问题分析 桌子上有一只盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。只有盘子空时，爸爸或妈妈才可向盘子中放一一个水果。仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。 互斥关系: 对缓冲区(盘子)的访问要互斥地进行 同步关系(一前一后) : 父亲将苹果放入盘子后，女儿才能取苹果 母亲将橘子放入盘子后，儿子才能取橘子 只有盘子为空时，父亲或母亲才能放入水果（“盘子为空”这个事件可以由儿子或女儿触发，事件发生后才允许父亲或母亲放水果） 2.整理思路。根据各进程的操作流程确定P、V操作的大致顺序。 3.设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。( 互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少) 原因在于:本题中的缓冲区大小为1，在任何时刻，apple、 orange、 plate 三个同步信号量中最多只有一个是1。最多只有一个进程的P操作不会被阻塞，并因此在任何时刻，顺利地进入临界区… 如果盘子（缓冲区）容量为2： 父亲P(plate)，可以访问盘子→母亲P(plate)，可以访问盘子&gt;父亲在往盘子里放苹果，同时母亲也可以往盘子里放橘子。于是就出现了两个进程同时访问缓冲区的情况，有可能导致两个进程写入缓冲区的数据相互覆盖的情况。因此，如果缓冲区大小大于1，就必须专门设置一个互斥信号量mutex来保证互斥访问缓冲区。 吸烟者问题 问题描述 假设一个系统有三个抽烟者进程和一-个供应者进程。每个抽烟者不停地卷烟并抽掉它，但是要卷起并抽掉一支烟， 抽烟者需要有三种材料:烟草、纸和胶水。三个抽烟者中，第一个拥有烟草、第二个拥有纸、第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它， 并给供应者进程-一个信号告诉完成了，供应者就会放另外两种材料再桌上，这个过程一直重复(让三个抽烟者轮流地抽烟)本质上这题也属于“生产者-消费者”问题，更详细的说应该是“可生产多种产品的单生产者—多消费者”。 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。 整理思路。根据各进程的操作流程确定P、V操作的大致顺序 设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。( 互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少) 如何实现 读者—写者问题 有读者和写者两组并发进程，共享-一个文件，当两个或两个以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程(读进程或写进程)同时访问共享数据时则可能导致数据不一致的错误。因此要求:①允许多个读者可以同时对文件执行读操作;②只允许一个写者往文件中写信息;③任一写者在完成写操作之前不允许其他读者或写者工作;④写者执行写操作前，应让已有的读者和写者全部退出。 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系 整理思路。根据各进程的操作流程确定P、V操作的大致顺序 设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。( 互斥信号量初值一般为1,同步信号量的初始值要看对应资源的初始值是多少) 两类进程:写进程、读进程 互斥关系:写进程-写进程、写进程一读进程。读进程与读进程不存在互斥问题。 写者进程和任何进程都互斥，设置一个互斥信号量rw,在写者访问共享文件前后分别执行P、V操作。读者进程和写者进程也要互斥，因此读者访问共享文件前后也要对rw执行P、V操作。 如果所有读者进程在访问共享文件之前都执行P(rw)操作，那么会导致各个读进程之间也无法同时访问文件。Key:读者写者问题的核心思想一-怎么处理该问题呢? P(rw)和V(rw)其实就是对共享文件的“加锁”和“解锁”。既然各个读进程需要同时访问，而读进程与写进程又必须互斥访问，那么我们可以让第一个访问文件的读进程“ 加锁”，让最后一个访问完文件的读进程“解锁”。可以设置一个整数变量count来记录当前有几个读进程在访问文件。 如何实现 哲学家进餐问题 一张圆桌上坐着5名哲学家，每两个哲学家之间的桌上摆-根筷子，桌子的中间是一碗米饭。哲学家们倾注毕生的精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时,才试图拿起左、右两根筷子(- -根一根地拿起)。如果筷子已在他人手上，则需等待。饥饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。 1.关系分析。系统中有5个哲学家进程，5位哲学家与左右邻居对其中间筷子的访问是互斥关系。 2.整理思路。这个问题中只有互斥关系，但与之前遇到的问题不同的事，每个哲学家进程需要同时持有两个临界资源才能开始吃饭。如何避免临界资源分配不当造成的死锁现象，是哲学家问题的精髓。 3.信号量设置。定义互斥信号量数组chopstick[5]={1,1,1,1,1}用于实现对5个筷子的互斥访问。并对哲学家按0~4编号，哲学家i左边的筷子编号为i，右边的筷子编号为(i+1)%5。 如果五个哲学家并发地拿起了自己左手边的筷子，每位哲学家循环等待右边的人放下筷子（阻塞）。发生“死锁”。这种解决方案不合理。× 第三种解决方法 更准确的说法应该是:各哲学家拿筷子这件事必须互斥的执行。这就保证了即使一个哲学家在拿筷子拿到一半时被阻塞，也不会有别的哲学家会继续尝试拿筷子。这样的话，当前正在吃饭的哲学家放下筷子后，被阻塞的哲学家就可以获得等待的筷子了。 管程 管程是一种特殊的软件模块，有这些部分组成: 局部于管程的共享数据结构说明; 对该数据结构进行操作的一-组过程; 对局部于管程的共享数据设置初始值的语句; 4.管程有一个名字。 管程的基本特征: 管程的基本特征: 一个进程只有通过调用管程内的过程才能进入管程访问共享数据; 每次仅允许一个进程在管程内执行某个内部过程。 死锁 死锁的概念 在并发环境下各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是“死锁”。发生死锁后若无外力干涉，这些进程都将无法向前推进。 死锁、饥饿、死循环的区别 死锁:各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。 饥饿:由于长期得不到想要的资源，某进程无法向前推进的现象。比如:在短进程优先(SPF) 算法中，若有源源不断的短进程到来，则长进程将一直得不到处理机， 从而发生长进程“饥饿”, 死循环:某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序员故意设计的。 死锁产生的必要条件 产生死锁必须同时满足一下四个条件，只 要其中任一条件不成立，死锁就不会发生。 互斥条件:只有对必须互斥使用的资源的争抢才会导致死锁( 如哲学家的筷子、打印机设备)。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的(因为进程不用阻塞等待这种资源)。 不剥夺条件:进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 请求和保持条件:进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 循环等待条件:存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。 注意!发生死锁时一定有循环等待，但是发生循环等待时未必死锁( 循环等待是死锁的必要不充分条件) 如果同类资源数大于1，则即使有循环等待，也未必发生死锁。但如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件了。 什么时候会发生死锁 对系统资源的竞争。各进程对不可剥夺的资源(如打印机)的竞争可能引起死锁，对可剥夺的资源(CPU)的竞争是不会引起死锁的。 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2分别申请并占有了资源R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请资源R1,两者会因为申请的资源被对方占有而阻塞，从而发生死锁。 信号量的使用不当也会造成死锁。如生产者~消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，就有可能导致死锁。( 可以把互斥信号量、同步信号量也看做是一-种抽象的系统资源) 总之，对不可剥夺资源的不合理分配，可能导致死锁。 死锁的处理策略 预防死锁。破坏死锁产生的四个必要条件中的一一个或几个。 避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁( 银行家算法) 死锁的检测和解除。允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁。 死锁的处理策略——预防死锁 破坏互斥条件 互斥条件:只有对必须互斥使用的资源的争抢才会导致死锁。 如果把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。比如: SPOOLing技术。操作系统可以采用SPOOLing技术把独占设备在逻辑.上改造成共享设备。比如，用SPOOLing技 术将打印机改造为共享设备…. 该策略的缺点:并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方还必须保护这种互斥性。因此，很多时候都无法破坏互斥条件。 破坏不剥夺条件 不剥夺条件:进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。 破坏不剥夺条件: 方案一:当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。 方案二:当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一-般需要考虑各进程的优先级(比如:剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用) 该策略的缺点: 1.实现起来比较复杂。 2.释放已获得的资源可能造成前一阶段工作的失效。因此这种方法一般只适用于易保存和恢复状态的资源，如CPU。 3.反复地申请和释放资源会增加系统开销，降低系统吞吐量。 4.若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都需要放弃，以后再重新申请。如果一直发生这样的情况，就会导致进程饥饿。 破坏请求和保持条件 请求和保持条件:进程已经保持了至少-一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。 可以采用静态分配方法，即进程在运行前- - 次申请完它所需要的全部资源，在它的资源未满足前,不让它投入运行。一旦投入运行后，这些资源就- -直归它所有，该进程就不会再请求别的任何资源了。 该策略实现起来简单，但也有明显的缺点: 有些资源可能只需要用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，资源利用率极低。另外，该策略也有可能导致某些进程饥饿。 破坏循坏等待条件 循环等待条件:存在一种进程资源的循环等待链，链中的每一个进程己获得的资源同时被下一个进程所请求。 可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源(即编号相同的资源)一次申请完。 原理分析:一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而就不会产生循环等待的现象。 该策略的缺点: 1.不方便增加新的设备，因为可能需要重新分配所有的编号; 2.进程实际使用资源的顺序可能和编号递增顺序不一致，会导致资源浪费; 3.必须按规定次序申请资源，用户编程麻烦。 死锁的处理策略——避免死锁（银行家算法） 所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。当然，安全序列可能有多个。 如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。 如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁(处于不安全状态未必就是发生了死锁，但发生死锁时–定是在不安全状态)因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。这也是“银行家算法”的核心思想。 银行家算法 假设系统中有n个进程，m种资源 每个进程在运行前先声明对各种资源的最大需求数，则可用一个n* m的矩阵(可用二维数组实现)表示所有进程对各种资源的最大需求数。不妨称为最大需求矩阵Max，Max[i, j]=K表示进程Pi最多需要K个资源Rj。同理，系统可以用一个n*m的分配矩阵Allocation表示对所有进程的资源分配情况。Max - Allocation =Need矩阵，表示各进程最多还需要多少各类资源。另外，还要用一个长度为m的一维数组Available表示当前系统中还有多少可用资源。 某进程Pi向系统申请资源，可用一个长度为m的一维数组Request,表示本次申请的各种资源量。 可用银行家算法预判本次分配是否会导致系统进入不安全状态: ①如果RequestijsNeed[i, jl (0sjsm)便转向②;否则认为出错。（因为它所需要的资源数已超过它所宣布的最大值。） ②如果Request[i]sAvailable[j] (0sjsm),便转向③;否则表示尚无足够资源，Pi必须等待。 ③系统试探着把资源分配给进程Pi，并修改相应的数据(并非真的分配，修改数值只是为了做预判) : Available = Available - Request; Allocation[i, j] = Allocation[i, j] + Request[i]; Need[i, j] = Need[i, j] - Request,[j] ④操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式分配;否则，恢复相应数据，让进程阻塞等待。 数据结构: 长度为m的一-维数组Available表示还有多少可用资源 n*m矩阵Max表示各进程对资源的最大需求数 n*m矩阵Allocation表示已经给各进程分配了多少资源 Max - Allocation = Need矩阵表示各进程最多还需要多少资源用长度为m的一-位数组Request表示进程此次申请的各种资源数 银行家算法步骤： ①检查此次申请是否超过了之前声明的最大需求数 ②检查此时系统剩余的可用资源是否还能满足这次请求 ③试探着分配，更改各数据结构 ④用安全性算法检查此次分配是否会导致系统进入不安全状态 安全性算法步骤: 检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列，并把该进程持有的资源全部回收。 不断重复上述过程，看最终是否能让所有进程都加入安全序列。 系统处于不安全状态未必死锁，但死锁时一定处于不安全状态。 系统处于安全状态一定不 会死锁。 死锁的处理策略——检测和解除 死锁的检测 为了能对系统是否已发生了死锁进行检测，必须: 用某种数据结构来保存资源的请求和分配信息: 提供一种算法， 利用上述信息来检测系统是否已进入死锁状态。 如果系统中剩余的可用资源数足够满足进程的需求，那么这个进程暂时是不会阻塞的，可以顺利地执行下去。如果这个进程执行结束了把资源归还系统，就可能使某些正在等待资源的进程被激活，并顺利地执行下去。相应的，这些被激活的进程执行完了之后又会归还一些资源，这样可能又会激活另外-些阻塞的进程… 如果按上述过程分析，最终能消除所有边，就称这个图是可完全简化的。此时- -定没有发生死锁(相当于能找到一个安全序列) 如果最终不能消除所有边，那么此时就是发生了死锁。 最终还连着边的那些进程就是处于死锁状态的进程。 检测死锁的算法: 1)在资源分配图中，找出既不阻塞又不是孤点的进程Pi (即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如下图中，R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源)。消去它所有的请求边和分配变，使之称为孤立的结点。在下图中，P1是满足这一条件的进程结点，于是将P1的所有边消去。 2)进程Pi所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在下图中，P2 就满足这样的条件。根据1)中的方法进行一系列简化后，若能消去途中所有的边，则称该图是可完全简化的。 死锁定理:如果某时刻系统的资源分配图是不可完全简化的，那么此时系统死锁 死锁的解除 一旦检测出死锁的发生，就应该立即解除死锁。 补充:并不是系统中所有的进程都是死锁状态，用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程那些进程就是死锁进程 解除死锁的主要方法有: 资源剥夺法。挂起(暂时放到外存上)某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是应防止被挂起的进程长时间得不到资源而饥饿。 撤销进程法(或称终止进程法)。强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑，以后还得从头再来。 进程回退法。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。 如何决定“对谁动手” 进程优先级 已执行多长时间 还要多久能完成 进程已经使用了多少资源 进程是交互式的还是批处","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://amourlover.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"IP基础知识","slug":"IP基础知识","date":"2020-05-11T13:56:21.000Z","updated":"2020-05-11T14:50:10.000Z","comments":true,"path":"2020/05/11/IP基础知识/","link":"","permalink":"http://amourlover.xyz/2020/05/11/IP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"https://mp.weixin.qq.com/s/qydIO7NDfFTYs4-ZZlfgRg 这是我在微信公众号上看到的一篇文章。","categories":[],"tags":[]},{"title":"操作系统第一章","slug":"操作系统","date":"2020-05-09T14:28:40.000Z","updated":"2020-05-30T14:16:10.000Z","comments":true,"path":"2020/05/09/操作系统/","link":"","permalink":"http://amourlover.xyz/2020/05/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"关于操作系统的一些基本概念","text":"关于操作系统的一些基本概念 操作系统的概念、功能和目标 概念 补充：进程是一个程序的执行过程，执行前需要将该程序放在内存中，才能被CPU处理。 功能和目标 作为系统资源的管理者 功能 ：1、处理机管理2、存储器管理3、文件管理4、设备管理 目标：安全、高效 作为用户和计算机硬件之间的接口 功能：1、命令接口（联机命令接口、脱机命令接口）2、程序接口——由一组系统调用组成3、GUI（即图形用户界面） 目标：方便用户使用 命令接口：允许用户直接使用 程序接口：允许用户通过程序简介使用=系统调用=广义指令 GUI：现代操作系统中最流行的图形用户接口 作为最接近硬件的层次——实现对硬件机器的拓展。 四个特征 操作系统的特征：并发、共享、虚拟、异步。并发和共享是两个最基本的特征，互为存在条件。 并发：指两个或多个事件在同一时间间隔发生。这些事件宏观上是同时发生的，但微观上是交替发生的。（并行：指两个或多个事件在同一时刻同时发生。） 共享：即资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。 两种资源共享方式：1、互斥共享方式——一个时间段内只允许一个进程访问该资源。2、同时共享方式——允许一个时间段内有多个进程“同时”对他们进行访问。 虚拟：是指把一个物理上的实体变为若干个逻辑上的对应物，物理实体（前者）是实际存在的，而逻辑上的对应物（后者）是用户感受到的。 虚拟技术：1、空分复用技术（如虚拟存储器技术）。2、时分复用技术（如虚拟处理器）。 没有并发性，就无虚拟性。 异步：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，以不可预知的速度向前推进。 只有系统拥有并发性，才有可能导致异步。 OS的发展与分类 手工操作阶段 主要缺点：用户独占全机，人机速度矛盾导致资源利用率极低。 批处理阶段——单道批处理系统 引入脱机输入/输出技术（用磁带完成），并监督程序（操作系统的雏形）负责控制作业的输入、输出。 主要优点：缓解了一定程度的人机速度矛盾，资源利用率有所提升。 主要缺点：内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序。CPU有大量的时间是在空闲等待I/O完成。资源利用率仍然很低。 批处理阶段——多道批处理系统 主要优点：多道程序并发执行，共享计算机资源。资源利用率大幅提升，CPU和其他资源保持”忙碌”状态，系统吞吐量增大。 主要缺点：用户响应时间长，没有人机交互功能（用户提交自己的作业之后就只能等待计算机处理完成，之间不能控制自己的作业执行）。 分时操作系统 计算机以时间片为单位轮流为各个用户/作业服务，各个用户可通过终端与计算机进行交互。 主要优点：用户请求可以被及时响应，解决了人机交互问题。允许多个用户同时使用一台计算机，并且用户对计算机的操作相互对立，感受不到别人的存在。 主要缺点：不能优先处理一些紧急任务。操作系统对各个用户/作业都是完全公平的，循环地为每个用户/作业服务一个时间片，不区分任务的紧急性。 实时操作系统 主要优点：能够优先响应一写紧急任务，某些紧急任务不需时间片排队。 在实时系统的控制下，计算机系统接收到外部信号后及时进行处理，并且要在严格的时限内处理完事件。实时操作系统的主要特点是及时性和可靠性。 实时操作系统分为：1、硬实时系统——必须在绝对严格的规定时间内完成处理（如：导弹控制系统、自动驾驶系统）。2、软实时系统——能接受偶尔违反时间规定（如：12306火车订票系统）。 运行机制与体系结构 运行机制 两种指令：1、特权指令：如内存清零指令（不允许用户程序使用。）2、非特权指令：如普通的运算指令。 两种处理器状态（用程序状态字寄存器（PSW）中的某标志位来标识当前处理器处于什么状态。如0为用户态，1为核心态)：1、用户态（目态）——此时CPU只执行非特权指令。2、核心态（管态）——特权指令、非特权指令都可以执行。 两种程序：1、内核程序——是系统的管理者，既可以执行特权指令，也可以执行非特权指令，运行在核心态。2、应用程序——为了保证系统能安全运行，普通应用程序只能执行非特权指令，运行在用户态。 操作系统的内核 内核是计算机上配置的底层软件，是操作系统最基本、最核心的部分。实现操作系统内核功能的那些程序就是内核程序。 操作系统的体系结构 中断和异常 中断机制的诞生 本质：发生中断就意味着需要操作系统介入，开展管理工作。 为了实现多道程序并发执行而引入的一种技术。 中断的概念和作用 当中断发生时，CPU立即进入核心态。 当中断发生后，当前运行的进程短暂运行，并由操作系统内核对中断进行处理。 对于不同的中断信号，会进行不同的处理。 “用户态—&gt;核心态”是通过中断实现的。并且中断是唯一途径。“核心态—&gt;用户态”的切换是通过执行一个特权指令，将程序状态字（PSW）的标志位设置为“用户态”。 中断的分类 内中断（也称异常、例外、陷入）：1、自愿中断——指令中断（如：系统调用时使用的访管指令（又叫陷入指令、trap指令））。2、强迫中断——硬件故障（如：缺页）、软件故障（如：整数除0）。 信号的来源：CPU内部，与当前执行的指令有关。 外中断（中断）：1、外设请求（如：I/O操作完成发出的中断信号）。2、人工干预（如：用户强行终止一个进程）。 信号的来源：CPU外部，与当前执行的指令无关。 另一种分类： 内中断（内部异常）：1、陷阱、陷入（trap）——有意而为之的异常，如系统调用。2、故障（fault）——由错误条件引起的，可能被故障处理程序修复，如缺页。3、终止（abort）——不可修复的致命错误造成的结果，终止处理程序不再将控制返回给引发终止的应用程序，如整数除0. 信号的来源：CPU内部，与当前执行的指令有关。 外中断（中断）：1、I/O中断请求。2、人工干预。 信号的来源：CPU外部，与当前执行的指令无关。 外中断的处理过程 执行完每个指令之后，CPU都要检查当前是否有外部中断信号。 如果检测到外部中断信号，则需要保护被中断进程的CPU环境（如程序状态字PSW、程序计数器PC、各种通用寄存器）。 根据中断信号类型转入相应的中断处理程序。 回复原进程的CPU环境并退出中断，返回原进程继续往下执行。 系统调用 什么是系统调用，有何作用 概念：“系统调用”是操作系统提供给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务。 作用：应用程序通过系统调用请求操作系统的服务。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，愤怒时与资源有关的操作（如存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统提出服务请求，由操作系统代为完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作。 系统调用（按功能分类）：1、设备管理——完成设备的请求/释放/启动等功能。2、文件管理——完成文件的读/写/创建/删除等功能。3、进程控制——完成进程的创建/撤销/阻塞/唤醒等功能。4、进程通信——完成进程之间的消息传递/信号传递等功能。5、内存管理——完成内存的分配/回收等功能。 系统调用相关处理涉及到对系统资源的管理、对进程的控制，这些功能需要一些特权指令才能完成，因此系统调用的相关处理需要在核心态下进行。 系统调用与库函数的区别 系统调用背后的过程 传递系统调用参数—&gt;执行陷入指令（用户态）—&gt;执行系统调用相应服务程序（核心态）—&gt;返回应用程序 注意：1、陷入指令是在用户态执行的，执行陷入指令之后立即引发一个内中断，从而CPU进入核心态。 2、发出系统调用请求是在用户态，而对系统调用的相应处理在核心态下进行。 3、陷入指令是指唯一一个只能在用户态执行，而不可在核心态执行的指令。","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://amourlover.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"30种常见颜色代码","slug":"30种常见颜色代码","date":"2020-05-09T11:18:08.000Z","updated":"2020-05-11T14:02:10.000Z","comments":true,"path":"2020/05/09/30种常见颜色代码/","link":"","permalink":"http://amourlover.xyz/2020/05/09/30%E7%A7%8D%E5%B8%B8%E8%A7%81%E9%A2%9C%E8%89%B2%E4%BB%A3%E7%A0%81/","excerpt":"参考资料：百度百科-颜色码","text":"参考资料：百度百科-颜色码 浅粉色 #FFB6C1 粉红 FFC0CB 猩红 #DC143C 脸红的淡紫色 #FFF0F5 苍白的紫罗兰红色#DB7093 热情的粉红 #FF69B4 深粉色 #FF1493 适中的紫罗兰红色 #C71585 兰花的紫色 #DA70D6 蓟 #D8BFD8 李子 #DDA0DD 紫罗兰 #EE82EE 洋红 #FF00FF 灯笼海棠（紫红）#FF00FF 深洋红色 #8B008B 紫色 #800080 适中的兰花紫 #BA55D3 深紫罗兰色 #9400D3 深兰花紫 #9932CC 靛青 #4B0082 深紫罗兰的蓝色 #8A2BE2 适中的紫色 #9370DB 暗蓝灰色 #7B68EE 板岩暗蓝灰色 #6A5ACD 深岩暗蓝灰色 #483D8B 薰衣草花的淡紫色 #E6E6FA 幽灵的白色 #F8F8FF 纯蓝 #0000FF 适中的蓝色 #0000CD 午夜的蓝色 #191970 深蓝色 #00008B 海军蓝 #000080 宝蓝 #4169E1 矢车菊的蓝色 #6495ED 淡钢蓝 #B0C4DE 爱丽丝蓝 #F0F8FF 钢蓝 #4682B4 淡蓝色 #87CEFA 天蓝色 #87CEEB","categories":[],"tags":[{"name":"颜色代码","slug":"颜色代码","permalink":"http://amourlover.xyz/tags/%E9%A2%9C%E8%89%B2%E4%BB%A3%E7%A0%81/"}]},{"title":"接口和抽象类的区别是什么？","slug":"接口和抽象类的区别是什么？","date":"2020-05-06T10:41:49.000Z","updated":"2020-05-06T10:44:40.000Z","comments":true,"path":"2020/05/06/接口和抽象类的区别是什么？/","link":"","permalink":"http://amourlover.xyz/2020/05/06/%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/","excerpt":"","text":"接口和抽象类的区别是什么？ 接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。 接口中除了 static、final 变量，不能有其他变量，而抽象类中则不一定。 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过 extends 关键字扩展多个接口。 接口方法默认修饰符是 public，抽象方法可以有 public、protected 和 default 这些修饰符（抽象方法就是为了被重写所以不能使用 private 关键字修饰！）。 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。 备注： 在 JDK8 中，接口也可以定义静态方法，可以直接用接口名调用。实现类和实现是不可以调用的。如果同时实现两个接口，接口中定义了一样的默认方法，则必须重写，不然会报错。(详见 issue:https://github.com/Snailclimb/JavaGuide/issues/146。 jdk9 的接口被允许定义私有方法 。 总结一下 jdk7~jdk9 Java 中接口概念的变化（相关阅读）： 在 jdk 7 或更早版本中，接口里面只能有常量变量和抽象方法。这些接口方法必须由选择实现接口的类实现。 jdk8 的时候接口可以有默认方法和静态方法功能。 Jdk 9 在接口中引入了私有方法和私有静态方法。","categories":[],"tags":[]},{"title":"Hexo-常用命令","slug":"Hexo-常用命令","date":"2020-05-06T10:15:10.000Z","updated":"2020-05-26T13:52:02.000Z","comments":true,"path":"2020/05/06/Hexo-常用命令/","link":"","permalink":"http://amourlover.xyz/2020/05/06/Hexo-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"（1）$ hexo g或$ hexo generate 该命令执行后在hexo站点根目录下生成public文件夹 （2）$ hexo clean 把（1）中的public文件夹删除 （3）$ hexo s或$ hexo server 启动服务预览 （4）$ hexo d或$ hexo deploy 部署站点，在本地生成.deploy_git文件夹，并将编译后的文件上传至 GitHub。 （5）$ hexo new [layout] 例如：$ hexo new photo “my-first-blog” 上述指令执行时，Hexo 会尝试在 scaffolds 中寻找photo.md布局，若找到，则根据该布局新建文章；若未找到或指令中未指定该参数，则使用post.md新建文章。新建文章的名称在_config.yml中配置。 （6）删除文章 只需在本地把source/_posts文件夹下的文章源文件删除后，执行以下命令重新部署即可。 12$ hexo clean // 一定要先 clean，防止灵异事件发生$ hexo s 作者：四喜汤圆链接：https://www.jianshu.com/p/7ba00af8da13来源：简书","categories":[],"tags":[]},{"title":"重载和重写的区别","slug":"重载和重写的区别","date":"2020-05-06T09:29:39.000Z","updated":"2020-06-04T16:26:45.903Z","comments":true,"path":"2020/05/06/重载和重写的区别/","link":"","permalink":"http://amourlover.xyz/2020/05/06/%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理 重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法 区别点 重载方法 重写方法 发生范围 同一个类 子类 中 参数列表 必须修改 一定不能修改 返回类型 可修改 一定不能修改 异常 可修改 可以减少或删除，一定不能抛出新的或者更广的异常 访问修饰符 可修改 一定不能做更严格的限制（可以降低限制） 发生阶段 编译期 运行期","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://amourlover.xyz/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"颜色代码","slug":"颜色代码","permalink":"http://amourlover.xyz/tags/%E9%A2%9C%E8%89%B2%E4%BB%A3%E7%A0%81/"}]}